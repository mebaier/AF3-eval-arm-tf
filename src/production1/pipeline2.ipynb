{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bb64e8",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bae167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functions_filtering import *\n",
    "\n",
    "import importlib\n",
    "import constants\n",
    "importlib.reload(constants)\n",
    "from constants import *\n",
    "\n",
    "import functions_analysis\n",
    "import functions_job_creation\n",
    "import functions_filtering\n",
    "import functions_plotting\n",
    "import functions_download\n",
    "import functions_pdb2net\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(functions_analysis)\n",
    "importlib.reload(functions_job_creation)\n",
    "importlib.reload(functions_filtering)\n",
    "importlib.reload(functions_download)\n",
    "importlib.reload(functions_plotting)\n",
    "importlib.reload(functions_pdb2net)\n",
    "\n",
    "from functions_analysis import *\n",
    "from functions_job_creation import *\n",
    "from functions_download import *\n",
    "from functions_filtering import *\n",
    "from functions_plotting import *\n",
    "from functions_pdb2net import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ace3d3",
   "metadata": {},
   "source": [
    "# 2. Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9865b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = pd.read_csv('/home/markus/MPI_local/data/PDB_reports/4/combined_pdb_reports_processed.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee940caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with NaN in sequence field\n",
    "print(f\"Before removing NaN sequences: {len(rep)}\")\n",
    "rep = rep.dropna(subset=['Sequence'])\n",
    "print(f\"After removing NaN sequences: {len(rep)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length filter\n",
    "MIN_LENGTH = 20\n",
    "\n",
    "print(f\"Before length filter: {len(rep)}\")\n",
    "rep['Sequence length'] = rep['Sequence'].fillna('').str.len()\n",
    "rep = rep[rep['Sequence length'] >= MIN_LENGTH]\n",
    "print(f\"After length filter: {len(rep)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = add_iupred3(rep, 'long', 'no', IUPRED_CACHE_DIR, IUPRED3_THRESHOLD, MIN_LENGTH_DISORDERED_REGION, IUPRED3_PATH, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all PDBs that don't have at least 1 disordered chain\n",
    "print(len(rep))\n",
    "keep_pdbs = set()\n",
    "for _, row in rep.iterrows():\n",
    "    if row['num_disordered_regions'] > 0:\n",
    "        keep_pdbs.add(row['Entry ID'])\n",
    "        \n",
    "rep = rep[rep['Entry ID'].isin(keep_pdbs)]\n",
    "\n",
    "print(len(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78150fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all PDBs that don't have at least 1 ordered chain\n",
    "print(len(rep))\n",
    "keep_pdbs = set()\n",
    "for _, row in rep.iterrows():\n",
    "    if row['num_disordered_regions'] == 0:\n",
    "        keep_pdbs.add(row['Entry ID'])\n",
    "        \n",
    "rep = rep[rep['Entry ID'].isin(keep_pdbs)]\n",
    "\n",
    "print(len(rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3227d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write into directory for PDB2Net processing\n",
    "PDB2NET_PREFIX = '/home/markus/PDB2Net/in/'\n",
    "path_prefix = PDB2NET_PREFIX + 'pipeline2/'\n",
    "rep['model_path'] = rep['Entry ID'].apply(lambda id: path_prefix + id.lower() + '.cif')\n",
    "\n",
    "rep.drop_duplicates(subset=['model_path'], inplace=False)['model_path'].to_csv(PDB2NET_PREFIX + 'pipeline2.csv', index=False)\n",
    "\n",
    "# download pdb structures for pdb2net\n",
    "download_pdb_structures(set(rep['Entry ID'].tolist()), path_prefix, 'cif', '/home/markus/MPI_local/data/PDB', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate interface\n",
    "# define interface as having at least INTERFACE_MIN_ATOMS atoms within INTERFACE_MAX_DISTANCE A of each other\n",
    "INTERFACE_MIN_ATOMS = 10\n",
    "INTERFACE_MAX_DISTANCE = 5 # higher not possible => change PDB2Net data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d716b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/markus/MPI_local/data/PDB2Net/pipeline2/2025-08-28_19-38-42'\n",
    "interfaces_df = get_interfaces_pdb2net(PATH, INTERFACE_MIN_ATOMS, INTERFACE_MAX_DISTANCE, set(rep['Entry ID'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b055768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate interfaces based on UniProt IDs\n",
    "print(f\"Before deduplication: {len(interfaces_df)} interfaces\")\n",
    "\n",
    "interfaces_df['normalized_uniprot'] = interfaces_df['Uniprot IDs'].apply(normalize_uniprot_pair)\n",
    "interfaces_df = interfaces_df.drop_duplicates(subset=['normalized_uniprot'])\n",
    "interfaces_df = interfaces_df.drop('normalized_uniprot', axis=1)\n",
    "\n",
    "print(f\"After deduplication: {len(interfaces_df)} interfaces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bbbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only interactions between ordered-disordered chain\n",
    "rep_reindex = rep.copy()\n",
    "\n",
    "rep_reindex.set_index(['Entry ID', 'Asym ID'], inplace=True)\n",
    "\n",
    "import json\n",
    "print(len(interfaces_df))\n",
    "\n",
    "for ind,row in interfaces_df.iterrows():\n",
    "    interface_id = json.loads(row['Interface ID'].replace('\\'', '\"'))\n",
    "    chainID_1 = interface_id[0]\n",
    "    chainID_2 = interface_id[1]\n",
    "    try:\n",
    "        disorder_chain1 = int(rep_reindex.loc[(row['Entry ID'], chainID_1), 'num_disordered_regions'])\n",
    "        disorder_chain2 = int(rep_reindex.loc[(row['Entry ID'], chainID_2), 'num_disordered_regions'])\n",
    "    except KeyError as e:\n",
    "        # Skip this interface if entry/chain not found\n",
    "        # print(f\"Entry not found: {e}\")\n",
    "        interfaces_df.drop(ind, inplace=True)\n",
    "        continue\n",
    "    disorder_chain1 = int(rep_reindex.loc[(row['Entry ID'], chainID_1), 'num_disordered_regions'])\n",
    "    disorder_chain2 = int(rep_reindex.loc[(row['Entry ID'], chainID_2), 'num_disordered_regions'])\n",
    "    \n",
    "    if not ((disorder_chain1 == 0 and disorder_chain2 >= 1) or (disorder_chain2 == 0 and disorder_chain1 >= 1)):\n",
    "        interfaces_df.drop(ind, inplace=True)\n",
    "        \n",
    "print(len(interfaces_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd03826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate interfaces with data\n",
    "interfaces_df['Release Date'] = interfaces_df['Entry ID'].map(rep.groupby('Entry ID')['Release Date'].first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaces_df['in_training_set'] = interfaces_df['Release Date'] <= AF_TRAINING_CUTOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29763d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_ids_structure_ds = interfaces_df['Uniprot IDs'].tolist()\n",
    "%store up_ids_structure_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3903ceb",
   "metadata": {},
   "source": [
    "# 3. Job Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functions_filtering import *\n",
    "\n",
    "import importlib\n",
    "import constants\n",
    "importlib.reload(constants)\n",
    "from constants import *\n",
    "\n",
    "import functions_analysis\n",
    "import functions_job_creation\n",
    "import functions_filtering\n",
    "import functions_plotting\n",
    "import functions_download\n",
    "import functions_pdb2net\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(functions_analysis)\n",
    "importlib.reload(functions_job_creation)\n",
    "importlib.reload(functions_filtering)\n",
    "importlib.reload(functions_download)\n",
    "importlib.reload(functions_plotting)\n",
    "importlib.reload(functions_pdb2net)\n",
    "\n",
    "from functions_analysis import *\n",
    "from functions_job_creation import *\n",
    "from functions_download import *\n",
    "from functions_filtering import *\n",
    "from functions_plotting import *\n",
    "from functions_pdb2net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_DIRS = []\n",
    "BATCH_DIRS.extend([os.path.join('../../production1/PDB_modelling/', d) for d in os.listdir('../../production1/PDB_modelling') if os.path.isdir(os.path.join('../../production1/PDB_modelling', d)) and 'batch' in d])\n",
    "\n",
    "interfaces_df.rename(columns={'Interface ID': 'Chains'}, inplace=True)\n",
    "new_af_jobs, reference_jobs = create_job_batch_from_PDB_chains(interfaces_df, BATCH_DIRS, 5120)\n",
    "write_af_jobs_to_individual_files(new_af_jobs, '../../production1/PDB_modelling/batch_12')\n",
    "write_af_jobs_to_individual_files(reference_jobs, '../../production1/PDB_modelling/reference', 'alphafold3', True)\n",
    "interfaces_df.rename(columns={'Chains': 'Interface ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e1fb5",
   "metadata": {},
   "source": [
    "# 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = interfaces_df.copy()\n",
    "results_df.rename(columns={'Chains': 'Interface ID'}, inplace=True)\n",
    "results_df.rename(columns={'pdb_id': 'Entry ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NATIVE_PATH_PREFIX = \"/home/markus/MPI_local/data/PDB/\"\n",
    "HPC_FULL_RESULTS_DIR = \"/home/markus/MPI_local/HPC_results_full\"\n",
    "PDB_CACHE = '../../production1/pdb_cache'\n",
    "DOCKQ_CACHE = '../../production1/dockq_cache_p2'\n",
    "JOB_DIR = '/home/markus/MPI_local/production1/PDB_modelling'\n",
    "# rename columns for compatibility with annotate_dockq()\n",
    "results_df['job_name'] = results_df.apply(lambda row: row['Entry ID'] + \"_\" + \"_\".join(eval(row['Interface ID'])), axis=1)\n",
    "results_df.rename(columns={'Entry ID': 'pdb_id'}, inplace=True)\n",
    "results_df, no_model = append_dockq_two_chainIDs(results_df, NATIVE_PATH_PREFIX, HPC_FULL_RESULTS_DIR, JOB_DIR, PDB_CACHE, DOCKQ_CACHE)\n",
    "results_df.rename(columns={'pdb_id': 'Entry ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa78bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(no_model)\n",
    "find_job_files(no_model, '/home/markus/MPI_local/production1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = annotate_AF_metrics(results_df, '/home/markus/MPI_local/HPC_results_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47547eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "create_scatter_plot_colour(results_df, 'iptm', 'dockq_score', 'in_training_set', ax=axes[0], corr=True)\n",
    "create_scatter_plot_colour(results_df, 'ptm', 'dockq_score',  'in_training_set', ax=axes[1], corr=True)\n",
    "create_scatter_plot(results_df, 'ranking_score', 'dockq_score', ax=axes[2], corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['interface_pae_max'] = results_df['chain_pair_pae_min'].apply(lambda c: max([c[0][1], c[1][0]]))\n",
    "results_df['interface_pae_min'] = results_df['chain_pair_pae_min'].apply(lambda c: min([c[0][1], c[1][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "create_scatter_plot(results_df, 'interface_pae_max', 'dockq_score', ax=axes[0], corr=True)\n",
    "create_scatter_plot(results_df, 'interface_pae_min', 'dockq_score', ax=axes[1], corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4098800",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['chain_pair_iptm_max'] = results_df['chain_pair_iptm'].apply(lambda c: max([c[0][0], c[1][1]]))\n",
    "results_df['chain_pair_iptm_min'] = results_df['chain_pair_iptm'].apply(lambda c: min([c[0][0], c[1][1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "create_scatter_plot(results_df, 'chain_pair_iptm_max', 'dockq_score', ax=axes[0], corr=True)\n",
    "create_scatter_plot(results_df, 'chain_pair_iptm_min', 'dockq_score', ax=axes[1], corr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39c1ea",
   "metadata": {},
   "source": [
    "## PR curve dockQ > 0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c172d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the metrics to evaluate\n",
    "metrics = ['iptm', 'ranking_score', 'ptm', 'chain_pair_iptm_max', 'chain_pair_iptm_min', \n",
    "           'interface_pae_max', 'interface_pae_min']\n",
    "\n",
    "# Create binary labels based on dockQ\n",
    "y_true = (results_df['dockq_score'] >= 0.80).astype(int)\n",
    "\n",
    "# Report number of 1s and 0s in y_true\n",
    "print(\"Dataset Class Distribution:\")\n",
    "print(f\"Total samples: {len(y_true)}\")\n",
    "print(f\"Positive samples (dockQ >= 0.80): {y_true.sum()} ({y_true.mean():.3f})\")\n",
    "print(f\"Negative samples (dockQ < 0.80): {len(y_true) - y_true.sum()} ({1 - y_true.mean():.3f})\")\n",
    "print()\n",
    "\n",
    "print(\"AUC Results and Optimal Cutoffs:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "auc_results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    # Get predictions (higher values should indicate better models for most metrics)\n",
    "    # For PAE metrics, we need to invert since lower PAE is better\n",
    "    if 'pae' in metric:\n",
    "        y_scores = -results_df[metric]  # Invert PAE scores\n",
    "        original_scores = results_df[metric]  # Keep original for cutoff reporting\n",
    "    else:\n",
    "        y_scores = results_df[metric]\n",
    "        original_scores = results_df[metric]\n",
    "    \n",
    "    # Remove NaN values\n",
    "    mask = ~(y_scores.isna() | y_true.isna())\n",
    "    y_scores_clean = y_scores[mask]\n",
    "    y_true_clean = y_true[mask]\n",
    "    original_scores_clean = original_scores[mask]\n",
    "    \n",
    "    if len(y_scores_clean) == 0:\n",
    "        print(f\"{metric}: No valid data\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate PR curve and AUC\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_true_clean, y_scores_clean)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true_clean, y_scores_clean)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Find optimal cutoffs\n",
    "    # 1. F1-score optimal cutoff (from PR curve)\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
    "    f1_scores = np.nan_to_num(f1_scores)  # Handle division by zero\n",
    "    optimal_f1_idx = np.argmax(f1_scores)\n",
    "    optimal_f1_threshold = pr_thresholds[optimal_f1_idx]\n",
    "    optimal_f1_score = f1_scores[optimal_f1_idx]\n",
    "    \n",
    "    # 2. Youden's J statistic optimal cutoff (from ROC curve)\n",
    "    # J = sensitivity + specificity - 1 = tpr - fpr\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_youden_idx = np.argmax(youden_j)\n",
    "    optimal_youden_threshold = roc_thresholds[optimal_youden_idx]\n",
    "    optimal_youden_j = youden_j[optimal_youden_idx]\n",
    "    \n",
    "    # Convert back to original scale for PAE metrics\n",
    "    if 'pae' in metric:\n",
    "        optimal_f1_threshold_original = -optimal_f1_threshold\n",
    "        optimal_youden_threshold_original = -optimal_youden_threshold\n",
    "    else:\n",
    "        optimal_f1_threshold_original = optimal_f1_threshold\n",
    "        optimal_youden_threshold_original = optimal_youden_threshold\n",
    "    \n",
    "    auc_results[metric] = {\n",
    "        'PR_AUC': pr_auc, \n",
    "        'ROC_AUC': roc_auc,\n",
    "        'optimal_f1_threshold': optimal_f1_threshold_original,\n",
    "        'optimal_f1_score': optimal_f1_score,\n",
    "        'optimal_youden_threshold': optimal_youden_threshold_original,\n",
    "        'optimal_youden_j': optimal_youden_j\n",
    "    }\n",
    "    \n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  PR-AUC: {pr_auc:.4f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"  Optimal F1 cutoff: {optimal_f1_threshold_original:.4f} (F1 = {optimal_f1_score:.4f})\")\n",
    "    print(f\"  Optimal Youden cutoff: {optimal_youden_threshold_original:.4f} (J = {optimal_youden_j:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall and ROC curves for ranking_score\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Get ranking_score data\n",
    "metric = 'ranking_score'\n",
    "y_scores = results_df[metric]\n",
    "\n",
    "# Remove NaN values\n",
    "mask = ~(y_scores.isna() | y_true.isna())\n",
    "y_scores_clean = y_scores[mask]\n",
    "y_true_clean = y_true[mask]\n",
    "\n",
    "# Calculate and plot PR curve\n",
    "precision, recall, _ = precision_recall_curve(y_true_clean, y_scores_clean)\n",
    "pr_auc = auc(recall, precision)\n",
    "ax1.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.4f})')\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title(f'Precision-Recall Curve - {metric}')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true_clean, y_scores_clean)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "ax2.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title(f'ROC Curve - {metric}')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nSummary for {metric}:\")\n",
    "print(f\"Total samples: {len(y_true_clean)}\")\n",
    "print(f\"Positive samples (dockq > 0.23): {y_true_clean.sum()}\")\n",
    "print(f\"Negative samples (dockq <= 0.23): {len(y_true_clean) - y_true_clean.sum()}\")\n",
    "print(f\"Baseline accuracy: {y_true_clean.sum() / len(y_true_clean):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
