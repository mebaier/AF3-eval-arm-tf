{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fada7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ad8fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 CSV files in /home/markus/MPI_local/data/PDB_reports/1\n",
      "  - rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_00001-02500.csv\n",
      "  - rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_02501-05000.csv\n",
      "  - rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_05001-07500.csv\n",
      "  - rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_07501-10000.csv\n",
      "  - rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_10001-12027.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the CSV files\n",
    "pdb_reports_dir = '/home/markus/MPI_local/data/PDB_reports/1'\n",
    "\n",
    "# Get all CSV files in the directory, sorted to maintain order\n",
    "csv_files = sorted(glob.glob(os.path.join(pdb_reports_dir, '*.csv')))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files in {pdb_reports_dir}\")\n",
    "for file in csv_files:\n",
    "    print(f\"  - {os.path.basename(file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47b8f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_00001-02500.csv...\n",
      "Reading rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_02501-05000.csv...\n",
      "Reading rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_05001-07500.csv...\n",
      "Reading rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_07501-10000.csv...\n",
      "Reading rcsb_pdb_custom_report_600ea47da61adfe8edd637fec8227fc9_10001-12027.csv...\n",
      "\n",
      "Combined dataframe shape: (43196, 15)\n",
      "Columns: ['Entry ID', 'Deposition Date', 'Release Date', 'PDB ID', 'Sequence', 'Entity Polymer Type', 'Total Number of polymer Entity Instances (Chains) per Entity', 'Source Organism', 'Taxonomy ID', 'Gene Name', 'Entity ID', 'Entry Id (Polymer Entity Identifiers)', 'Accession Code(s)', 'Database Name', 'Unnamed: 14']\n",
      "\n",
      "First 5 rows:\n",
      "  Entry ID Deposition Date Release Date PDB ID  \\\n",
      "0     1NVP      2003-02-04   2003-10-21   1NVP   \n",
      "1      NaN             NaN          NaN    NaN   \n",
      "2      NaN             NaN          NaN    NaN   \n",
      "3      NaN             NaN          NaN    NaN   \n",
      "4      NaN             NaN          NaN    NaN   \n",
      "\n",
      "                                            Sequence Entity Polymer Type  \\\n",
      "0                                  GGGGGGGCTATAAAAGG                 DNA   \n",
      "1                                  CCTTTTATAGCCCCCCC                 DNA   \n",
      "2  SGIVPQLQNIVSTVNLGCKLDLKTIALRARNAEYNPKRFAAVIMRI...             Protein   \n",
      "3  ANSANTNTVPKLYRSVIEDVINDVRDIFLDDGVDEQVLMELKTLWE...             Protein   \n",
      "4  GSGAEDGQVEEEPLNSEDDVSDEEGQELFDTENVVVCQYDKIHRSK...             Protein   \n",
      "\n",
      "   Total Number of polymer Entity Instances (Chains) per Entity  \\\n",
      "0                                                1.0              \n",
      "1                                                1.0              \n",
      "2                                                1.0              \n",
      "3                                                1.0              \n",
      "4                                                1.0              \n",
      "\n",
      "  Source Organism  Taxonomy ID             Gene Name  Entity ID  \\\n",
      "0             NaN          NaN                   NaN        1.0   \n",
      "1             NaN          NaN                   NaN        2.0   \n",
      "2    Homo sapiens       9606.0  TBP OR TFIID OR TF2D        3.0   \n",
      "3    Homo sapiens       9606.0       GTF2A1 OR TF2A1        4.0   \n",
      "4    Homo sapiens       9606.0       GTF2A1 OR TF2A1        5.0   \n",
      "\n",
      "  Entry Id (Polymer Entity Identifiers) Accession Code(s) Database Name  \\\n",
      "0                                  1NVP               NaN           NaN   \n",
      "1                                  1NVP               NaN           NaN   \n",
      "2                                  1NVP            P20226       UniProt   \n",
      "3                                  1NVP            P52655       UniProt   \n",
      "4                                  1NVP            P52655       UniProt   \n",
      "\n",
      "   Unnamed: 14  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "Missing values in key columns:\n",
      "Entry ID: 31169 missing values\n",
      "Deposition Date: 31169 missing values\n",
      "Release Date: 31169 missing values\n",
      "PDB ID: 31169 missing values\n",
      "\n",
      "Combined dataframe shape: (43196, 15)\n",
      "Columns: ['Entry ID', 'Deposition Date', 'Release Date', 'PDB ID', 'Sequence', 'Entity Polymer Type', 'Total Number of polymer Entity Instances (Chains) per Entity', 'Source Organism', 'Taxonomy ID', 'Gene Name', 'Entity ID', 'Entry Id (Polymer Entity Identifiers)', 'Accession Code(s)', 'Database Name', 'Unnamed: 14']\n",
      "\n",
      "First 5 rows:\n",
      "  Entry ID Deposition Date Release Date PDB ID  \\\n",
      "0     1NVP      2003-02-04   2003-10-21   1NVP   \n",
      "1      NaN             NaN          NaN    NaN   \n",
      "2      NaN             NaN          NaN    NaN   \n",
      "3      NaN             NaN          NaN    NaN   \n",
      "4      NaN             NaN          NaN    NaN   \n",
      "\n",
      "                                            Sequence Entity Polymer Type  \\\n",
      "0                                  GGGGGGGCTATAAAAGG                 DNA   \n",
      "1                                  CCTTTTATAGCCCCCCC                 DNA   \n",
      "2  SGIVPQLQNIVSTVNLGCKLDLKTIALRARNAEYNPKRFAAVIMRI...             Protein   \n",
      "3  ANSANTNTVPKLYRSVIEDVINDVRDIFLDDGVDEQVLMELKTLWE...             Protein   \n",
      "4  GSGAEDGQVEEEPLNSEDDVSDEEGQELFDTENVVVCQYDKIHRSK...             Protein   \n",
      "\n",
      "   Total Number of polymer Entity Instances (Chains) per Entity  \\\n",
      "0                                                1.0              \n",
      "1                                                1.0              \n",
      "2                                                1.0              \n",
      "3                                                1.0              \n",
      "4                                                1.0              \n",
      "\n",
      "  Source Organism  Taxonomy ID             Gene Name  Entity ID  \\\n",
      "0             NaN          NaN                   NaN        1.0   \n",
      "1             NaN          NaN                   NaN        2.0   \n",
      "2    Homo sapiens       9606.0  TBP OR TFIID OR TF2D        3.0   \n",
      "3    Homo sapiens       9606.0       GTF2A1 OR TF2A1        4.0   \n",
      "4    Homo sapiens       9606.0       GTF2A1 OR TF2A1        5.0   \n",
      "\n",
      "  Entry Id (Polymer Entity Identifiers) Accession Code(s) Database Name  \\\n",
      "0                                  1NVP               NaN           NaN   \n",
      "1                                  1NVP               NaN           NaN   \n",
      "2                                  1NVP            P20226       UniProt   \n",
      "3                                  1NVP            P52655       UniProt   \n",
      "4                                  1NVP            P52655       UniProt   \n",
      "\n",
      "   Unnamed: 14  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "Missing values in key columns:\n",
      "Entry ID: 31169 missing values\n",
      "Deposition Date: 31169 missing values\n",
      "Release Date: 31169 missing values\n",
      "PDB ID: 31169 missing values\n"
     ]
    }
   ],
   "source": [
    "# Read all CSV files and combine them into a single dataframe\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"Reading {os.path.basename(file_path)}...\")\n",
    "    \n",
    "    # Read each CSV file, skipping first row and using second row as headers\n",
    "    df = pd.read_csv(file_path, skiprows=1, header=0)\n",
    "    \n",
    "    # Append to the combined dataframe\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "print(f\"\\nCombined dataframe shape: {combined_df.shape}\")\n",
    "print(f\"Columns: {list(combined_df.columns)}\")\n",
    "\n",
    "# Display first few rows to understand the structure\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Check for missing values in key columns\n",
    "key_columns = ['Entry ID', 'Deposition Date', 'Release Date', 'PDB ID']\n",
    "print(\"\\nMissing values in key columns:\")\n",
    "for col in key_columns:\n",
    "    if col in combined_df.columns:\n",
    "        missing_count = combined_df[col].isna().sum()\n",
    "        print(f\"{col}: {missing_count} missing values\")\n",
    "    else:\n",
    "        print(f\"{col}: Column not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "719894dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values...\n",
      "Missing values after filling:\n",
      "Entry ID: 0 missing values\n",
      "Deposition Date: 0 missing values\n",
      "Release Date: 0 missing values\n",
      "PDB ID: 0 missing values\n",
      "\n",
      "Sample of processed data:\n",
      "  Entry ID Deposition Date Release Date PDB ID\n",
      "0     1NVP      2003-02-04   2003-10-21   1NVP\n",
      "1     1NVP      2003-02-04   2003-10-21   1NVP\n",
      "2     1NVP      2003-02-04   2003-10-21   1NVP\n",
      "3     1NVP      2003-02-04   2003-10-21   1NVP\n",
      "4     1NVP      2003-02-04   2003-10-21   1NVP\n",
      "5     1NVP      2003-02-04   2003-10-21   1NVP\n",
      "6     5GPY      2016-08-05   2016-11-02   5GPY\n",
      "7     5GPY      2016-08-05   2016-11-02   5GPY\n",
      "8     8CLL      2023-02-16   2023-06-21   8CLL\n",
      "9     8CLL      2023-02-16   2023-06-21   8CLL\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in key columns using forward fill\n",
    "# This fills each missing value with the last valid value that appeared before it\n",
    "print(\"Filling missing values...\")\n",
    "\n",
    "# Make a copy of the dataframe for processing\n",
    "processed_df = combined_df.copy()\n",
    "\n",
    "# Define the columns that need forward filling\n",
    "columns_to_fill = ['Entry ID', 'Deposition Date', 'Release Date', 'PDB ID']\n",
    "\n",
    "# Apply forward fill to each column\n",
    "for col in columns_to_fill:\n",
    "    if col in processed_df.columns:\n",
    "        # forward fill\n",
    "        processed_df[col] = processed_df[col].ffill()\n",
    "\n",
    "print(\"Missing values after filling:\")\n",
    "for col in columns_to_fill:\n",
    "    if col in processed_df.columns:\n",
    "        missing_count = processed_df[col].isna().sum()\n",
    "        print(f\"{col}: {missing_count} missing values\")\n",
    "\n",
    "# Display a sample of the processed data\n",
    "print(\"\\nSample of processed data:\")\n",
    "print(processed_df[columns_to_fill].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3905378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data to: /home/markus/MPI_local/data/PDB_reports/1/combined_pdb_reports_processed.csv\n",
      "Successfully saved 43196 rows to /home/markus/MPI_local/data/PDB_reports/1/combined_pdb_reports_processed.csv\n",
      "Final dataframe shape: (43196, 15)\n",
      "\n",
      "Summary of the final processed dataset:\n",
      "- Total rows: 43196\n",
      "- Unique PDB IDs: 12027\n",
      "- Date range: 1995-01-06 to 2025-06-29\n",
      "Successfully saved 43196 rows to /home/markus/MPI_local/data/PDB_reports/1/combined_pdb_reports_processed.csv\n",
      "Final dataframe shape: (43196, 15)\n",
      "\n",
      "Summary of the final processed dataset:\n",
      "- Total rows: 43196\n",
      "- Unique PDB IDs: 12027\n",
      "- Date range: 1995-01-06 to 2025-06-29\n"
     ]
    }
   ],
   "source": [
    "# Save the processed dataframe to a new CSV file\n",
    "output_file = os.path.join(pdb_reports_dir, 'combined_pdb_reports_processed.csv')\n",
    "\n",
    "print(f\"Saving processed data to: {output_file}\")\n",
    "processed_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Successfully saved {len(processed_df)} rows to {output_file}\")\n",
    "print(f\"Final dataframe shape: {processed_df.shape}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary of the final processed dataset:\")\n",
    "print(f\"- Total rows: {len(processed_df)}\")\n",
    "print(f\"- Unique PDB IDs: {processed_df['PDB ID'].nunique() if 'PDB ID' in processed_df.columns else 'N/A'}\")\n",
    "print(f\"- Date range: {processed_df['Deposition Date'].min() if 'Deposition Date' in processed_df.columns else 'N/A'} to {processed_df['Deposition Date'].max() if 'Deposition Date' in processed_df.columns else 'N/A'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
