{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a438be9d",
   "metadata": {},
   "source": [
    "This file is used to create a dataset of structures of known interactions.\n",
    "Steps:\n",
    "1. generate dataset of ARMs and TFs\n",
    "2. For all ARMs and TFs: run BLASTp against the pdb database\n",
    "3. Create intersection of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from typing import List\n",
    "\n",
    "BLAST_BIN: str = \"blastp\"\n",
    "BLAST_DB: str = \"/home/markus/MPI_local/data/BLAST_PDB/pdbaa/pdbaa\"\n",
    "E_VAL_CUTOFF: str = \"0.00001\"\n",
    "TF_QUERY_DIR: str = '../../production1/tf_fasta'\n",
    "ARM_QUERY_DIR: str = '../../production1/arm_fasta'\n",
    "TF_OUTPUT_DIR: str = '../../production1/tf_blastp_no_e_lim'\n",
    "ARM_OUTPUT_DIR: str = '../../production1/arm_blastp_no_e_lim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blastp(fasta_path: str, output_path: str) -> None:\n",
    "    if os.path.exists(fasta_path):\n",
    "        try:\n",
    "            subprocess.run([\n",
    "                BLAST_BIN,\n",
    "                \"-query\", fasta_path,\n",
    "                \"-db\", BLAST_DB,\n",
    "                # \"-evalue\", E_VAL_CUTOFF,\n",
    "                \"-out\", output_path,\n",
    "                \"-outfmt\", \"7\"\n",
    "            ], check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"BLAST error for {fasta_path}: {e}\")\n",
    "    else:\n",
    "        raise Exception(f\"No FASTA file found: {fasta_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "def blastp_for_dir(input_dir: str, output_dir: str) -> None:\n",
    "    fasta_files: List[Path] = list(Path(input_dir).glob('*.fasta'))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    i: int = 0\n",
    "    duplicates: int = 0\n",
    "    for fasta_file in fasta_files:\n",
    "            if i % 25 == 0:\n",
    "                print(f\"{i} of {len(fasta_files)}\")\n",
    "\n",
    "            fasta_path: Path = fasta_file\n",
    "            uid: str = fasta_file.stem\n",
    "            output_path: str = os.path.join(output_dir, f\"{uid}_blastp.out\")\n",
    "            \n",
    "            if os.path.exists(output_path):\n",
    "                # print(f\"Skipping {uid}, output already exists.\")\n",
    "                duplicates += 1\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            run_blastp(str(fasta_path), output_path)\n",
    "            i += 1\n",
    "    print(f\"Found {i} proteins in {input_dir}.\\nRan blastp on {i-duplicates} proteins.\\nFound existing blast file for {duplicates} proteins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "blastp_for_dir(TF_QUERY_DIR, TF_OUTPUT_DIR)\n",
    "blastp_for_dir(ARM_QUERY_DIR, ARM_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea05c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLAST_IDENTITY_CUTOFF: int = 0\n",
    "BLAST_SCORE_CUTOFF: int = 50\n",
    "\n",
    "def clean_blastp_out(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['pdb_id'] = df['subject'].apply(lambda x: x.split('_')[0] if '_' in x else x)\n",
    "    df['chain'] = df['subject'].apply(lambda x: x.split('_')[1] if len(x.split('_')) > 1 else '')\n",
    "    df = df.drop_duplicates(subset='subject')\n",
    "    df['%identity'] = pd.to_numeric(df['%identity'], errors='raise')\n",
    "    df = df[df['%identity'] >= BLAST_IDENTITY_CUTOFF]\n",
    "    df['bit score'] = pd.to_numeric(df['bit score'], errors='raise')\n",
    "    df = df[df['bit score'] >= BLAST_SCORE_CUTOFF]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "columns: List[str] = [\n",
    "    \"query\", \"subject\", \"%identity\", \"alignment length\", \"mismatches\", \"gap opens\",\n",
    "    \"q. start\", \"q. end\", \"s. start\", \"s. end\", \"evalue\", \"bit score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d50201",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_TOP_N: int = 100\n",
    "\n",
    "def read_blast_to_df(output_dir: str, column_names: List[str]) -> pd.DataFrame:\n",
    "    output_files: List[Path] = list(Path(output_dir).glob('*_blastp.out'))\n",
    "    output_list: List[List[str]] = []\n",
    "    \n",
    "    for output_file in output_files:\n",
    "        try:\n",
    "            with open(output_file, 'r') as f:\n",
    "                lines: List[str] = [line for line in f if not line.startswith('#')]\n",
    "            # output_list.append(lines[:KEEP_TOP_N]) # only keep top 10 rows to reduce size\n",
    "            output_list.append(lines)\n",
    "        except IOError as e:\n",
    "            print(f\"Error reading file {output_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Flatten the list of lines and split by tab to create rows\n",
    "    rows: List[List[str]] = [line.strip().split('\\t') for file_lines in output_list for line in file_lines if line.strip()]\n",
    "    \n",
    "    if not rows:\n",
    "        print(f\"Warning: No data found in {output_dir}\")\n",
    "        return pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    out_df: pd.DataFrame = pd.DataFrame(rows, columns=column_names)\n",
    "    out_df = clean_blastp_out(out_df)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_blast_df: pd.DataFrame = read_blast_to_df(TF_OUTPUT_DIR, columns)\n",
    "print(len(tf_blast_df))\n",
    "arm_blast_df: pd.DataFrame = read_blast_to_df(ARM_OUTPUT_DIR, columns)\n",
    "print(len(arm_blast_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa845f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_df: pd.DataFrame = tf_blast_df.merge(arm_blast_df, how='inner', on='pdb_id')\n",
    "print(f\"Intersection contains {len(intersect_df)} structures\")\n",
    "\n",
    "# filter out candidates with same chains\n",
    "intersect_df = intersect_df[intersect_df['chain_x'] != intersect_df['chain_y']]\n",
    "\n",
    "if len(intersect_df) > 0:\n",
    "    display(intersect_df[['pdb_id', 'query_x', 'query_y', 'chain_x', 'chain_y', 'subject_x', 'subject_y', '%identity_x', '%identity_y']])\n",
    "else:\n",
    "    print(\"Warning: No intersecting structures found between TF and ARM BLAST results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_BA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
